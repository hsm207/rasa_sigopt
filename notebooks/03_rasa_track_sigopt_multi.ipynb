{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use SigOpt to optimize a rasa NLU model for both intent classification and entity extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 13:49:29.939861: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-31 13:49:29.940050: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "import rasa.shared.data as data\n",
    "import sigopt\n",
    "from rasa.engine.recipes.recipe import Recipe\n",
    "from rasa.model_testing import test_core, test_nlu\n",
    "from rasa.model_training import (\n",
    "    DaskGraphRunner,\n",
    "    GraphTrainer,\n",
    "    LocalTrainingCache,\n",
    "    Path,\n",
    "    TrainingResult,\n",
    "    _create_model_storage,\n",
    "    _determine_model_name,\n",
    ")\n",
    "from rasa.shared.importers.autoconfig import TrainingType\n",
    "from rasa.shared.importers.importer import TrainingDataImporter\n",
    "import json\n",
    "import time\n",
    "import asyncio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup sigopt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sigopt config --api-token $SIGOPT_API_TOKEN --enable-log-collection --enable-cell-tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sigopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move to the bot's root directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/rasa_sigopt/bot_sigopt\n"
     ]
    }
   ],
   "source": [
    "%cd ../bot_sigopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths to rasa configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"config.yml\"\n",
    "training_files = \"data\"\n",
    "validation_files = \"tests\"\n",
    "domain = \"domain.yml\"\n",
    "models = \"models\"\n",
    "test_results = \"results\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to do the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, file_importer, output_path=\"models\", training_type=TrainingType.BOTH):\n",
    "    recipe = Recipe.recipe_for_name(config.get(\"recipe\"))\n",
    "    model_configuration = recipe.graph_config_for_recipe(\n",
    "        config,\n",
    "        cli_parameters={},\n",
    "        training_type=training_type,\n",
    "    )\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as temp_model_dir:\n",
    "        model_storage = _create_model_storage(\n",
    "            is_finetuning=False,\n",
    "            model_to_finetune=None,\n",
    "            temp_model_dir=Path(temp_model_dir),\n",
    "        )\n",
    "        cache = LocalTrainingCache()\n",
    "        trainer = GraphTrainer(model_storage, cache, DaskGraphRunner)\n",
    "\n",
    "        model_name = _determine_model_name(\n",
    "            fixed_model_name=None, training_type=training_type\n",
    "        )\n",
    "\n",
    "        full_model_path = Path(output_path, model_name)\n",
    "\n",
    "        trainer.train(\n",
    "            model_configuration,\n",
    "            file_importer,\n",
    "            full_model_path,\n",
    "            force_retraining=False,\n",
    "            is_finetuning=False,\n",
    "        )\n",
    "\n",
    "        return TrainingResult(str(full_model_path), 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to extract some metrics from the test: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metric(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "\n",
    "    return metrics[\"weighted avg\"][\"f1-score\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to get the config for the DIET Classifier from a config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_diet_config = lambda config: [\n",
    "    component\n",
    "    for component in config[\"pipeline\"]\n",
    "    if component[\"name\"] == \"DIETClassifier\"\n",
    "][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that will train and evaluate and nlu model given the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def train_and_evaluate_nlu_model(config, file_importer, validation_path):\n",
    "    start_time = time.time()\n",
    "\n",
    "    nlu_training_results = train(config, file_importer, training_type=TrainingType.NLU)\n",
    "\n",
    "    model_path = nlu_training_results.model\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as temp_results_dir:\n",
    "        await test_nlu(\n",
    "            model=model_path,\n",
    "            nlu_data=validation_path,\n",
    "            output_directory=temp_results_dir,\n",
    "            additional_arguments={},\n",
    "        )\n",
    "\n",
    "        f1_intent = extract_metric(f\"{temp_results_dir}/intent_report.json\")\n",
    "        f1_entity = extract_metric(f\"{temp_results_dir}/DIETClassifier_report.json\")\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    return {\n",
    "        \"f1_intent\": f1_intent,\n",
    "        \"f1_entity\": f1_entity,\n",
    "        \"elapsed_time\": end_time - start_time,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to instrument the `train_and_evaluate_nlu_model` function in sigopt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_and_track_in_sigopt():\n",
    "    sigopt.log_dataset(\"Ask Ubuntu Corpus\")\n",
    "    sigopt.log_model(\"Default NLU Pipeline\")\n",
    "    file_importer = TrainingDataImporter.load_from_config(\n",
    "        config, domain, training_files\n",
    "    )\n",
    "\n",
    "    all_config = file_importer.get_config()\n",
    "    diet_config = get_diet_config(all_config)\n",
    "\n",
    "    sigopt.params.setdefault(\"epochs\")\n",
    "    sigopt.params.setdefault(\"embedding_dimension\")\n",
    "    sigopt.params.setdefault(\"number_of_transformer_layers\")\n",
    "    sigopt.params.setdefault(\"transformer_size\")\n",
    "\n",
    "    diet_config[\"epochs\"] = sigopt.params.epochs\n",
    "    diet_config[\"embedding_dimension\"] = 20\n",
    "    diet_config[\"number_of_transformer_layers\"] = 2\n",
    "    diet_config[\"transformer_size\"] = 256\n",
    "\n",
    "    results = await train_and_evaluate_nlu_model(all_config, file_importer, \"tests\")\n",
    "\n",
    "    sigopt.log_metric(name=\"f1-score (intent)\", value=results[\"f1_intent\"])\n",
    "    sigopt.log_metric(name=\"f1-score (entity)\", value=results[\"f1_entity\"])\n",
    "    sigopt.log_metric(name=\"total time (s)\", value=results[\"elapsed_time\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the experiment configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment created, view it on the SigOpt dashboard at https://app.sigopt.com/experiment/480092\n"
     ]
    }
   ],
   "source": [
    "%%experiment\n",
    "{\n",
    "    'name': 'NLU Optimization on Ask Ubuntu Corpus - Multi Obj',\n",
    "    'type': 'offline',\n",
    "    'metrics': [\n",
    "        {\n",
    "            'name': 'f1-score (intent)',\n",
    "            'strategy': 'constraint',\n",
    "            'objective': 'maximize',\n",
    "            'threshold': 0.85\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            'name': 'f1-score (entity)',\n",
    "            'strategy': 'constraint',\n",
    "            'objective': 'maximize',\n",
    "            'threshold': 0.85\n",
    "        }\n",
    "    ],\n",
    "    'parameters': [\n",
    "        {\n",
    "            'name': 'epochs',\n",
    "            'type': 'int',\n",
    "            'bounds': {'min': 1, 'max': 1000}\n",
    "        },\n",
    "        {\n",
    "            'name': 'embedding_dimension',\n",
    "            'type': 'int',\n",
    "            'bounds': {'min': 16, 'max': 1024}\n",
    "        },\n",
    "        {\n",
    "            'name': 'number_of_transformer_layers',\n",
    "            'type': 'int',\n",
    "            'bounds': {'min': 0, 'max': 8}\n",
    "        },\n",
    "        {\n",
    "            'name': 'transformer_size',\n",
    "            'type': 'int',\n",
    "            'bounds': {'min': 16, 'max': 1024}\n",
    "        },\n",
    "    ],\n",
    "    'budget': 50,\n",
    "    'parallel_bandwidth': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started, view it on the SigOpt dashboard at https://app.sigopt.com/run/157689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m/opt/venv/lib/python3.8/site-packages/rasa/shared/core/slot_mappings.py:212: UserWarning: Slot auto-fill has been removed in 3.0 and replaced with a new explicit mechanism to set slots. Please refer to https://rasa.com/docs/rasa/domain#slots to learn more.\n",
      "  rasa.shared.utils.io.raise_warning(\n",
      "\u001b[0m/opt/venv/lib/python3.8/site-packages/rasa/utils/tensorflow/model_data_utils.py:396: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([v[0] for v in values]), number_of_dimensions=3\n",
      "2022-01-31 13:49:47.959852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-31 13:49:47.959906: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-31 13:49:47.959939: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (00546656b663): /proc/driver/nvidia/version does not exist\n",
      "2022-01-31 13:49:47.960160: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/venv/lib/python3.8/site-packages/rasa/utils/tensorflow/model_data.py:750: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.concatenate(np.array(f)),\n",
      "Epochs:   0%|          | 0/511 [00:00<?, ?it/s]2022-01-31 13:49:48.145007: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "/opt/venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "Epochs: 100%|##########| 511/511 [04:57<00:00,  1.72it/s, t_loss=0.456, i_acc=1, e_f1=1]       \n",
      "\u001b[93m/opt/venv/lib/python3.8/site-packages/rasa/shared/core/slot_mappings.py:212: UserWarning: Slot auto-fill has been removed in 3.0 and replaced with a new explicit mechanism to set slots. Please refer to https://rasa.com/docs/rasa/domain#slots to learn more.\n",
      "  rasa.shared.utils.io.raise_warning(\n",
      "\u001b[0m/opt/venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "100%|##########| 35/35 [00:03<00:00, 11.05it/s]\n",
      "/opt/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/lib/python3.8/site-packages/rasa/utils/plotting.py:284: UserWarning: Attempting to set identical bottom == top == 1.0 results in singular transformations; automatically expanding.\n",
      "  axes[side].set(yticks=yticks, xlim=(0, x_ranges[side]), ylim=y_range)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished, view it on the SigOpt dashboard at https://app.sigopt.com/run/157689\n",
      "Run started, view it on the SigOpt dashboard at https://app.sigopt.com/run/157692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m/opt/venv/lib/python3.8/site-packages/rasa/shared/core/slot_mappings.py:212: UserWarning: Slot auto-fill has been removed in 3.0 and replaced with a new explicit mechanism to set slots. Please refer to https://rasa.com/docs/rasa/domain#slots to learn more.\n",
      "  rasa.shared.utils.io.raise_warning(\n",
      "\u001b[0m/opt/venv/lib/python3.8/site-packages/rasa/utils/tensorflow/model_data_utils.py:396: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([v[0] for v in values]), number_of_dimensions=3\n",
      "/opt/venv/lib/python3.8/site-packages/rasa/utils/tensorflow/model_data.py:750: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.concatenate(np.array(f)),\n",
      "Epochs:   0%|          | 0/56 [00:00<?, ?it/s]/opt/venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "Epochs: 100%|##########| 56/56 [00:49<00:00,  1.12it/s, t_loss=1.97, i_acc=1, e_f1=0.844]    \n",
      "\u001b[93m/opt/venv/lib/python3.8/site-packages/rasa/shared/core/slot_mappings.py:212: UserWarning: Slot auto-fill has been removed in 3.0 and replaced with a new explicit mechanism to set slots. Please refer to https://rasa.com/docs/rasa/domain#slots to learn more.\n",
      "  rasa.shared.utils.io.raise_warning(\n",
      "\u001b[0m/opt/venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "100%|##########| 35/35 [00:03<00:00, 11.42it/s]\n",
      "/opt/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%optimize Intent Classification and Entity Extraction Optimization\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(run_and_track_in_sigopt())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
